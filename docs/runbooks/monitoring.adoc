= Monitoring & Observability Runbook

This runbook details the key metrics, alerts, and tracing capabilities of the Helios Rule Engine. It is designed to help operators understand the system's health and performance.

== 1. Core Metrics

The engine exposes Prometheus-compatible metrics.

=== 1.1. Throughput & Latency
*   `helios_events_processed_total`: Counter. Total number of events processed.
*   `helios_evaluation_latency_seconds`: Histogram. Distribution of evaluation time per event.
    *   *Target*: P99 < 1ms.
*   `helios_rules_matched_total`: Counter. Total number of rules matched.

=== 1.2. Caching
*   `helios_cache_hits_total`: Counter. Number of base condition cache hits.
*   `helios_cache_misses_total`: Counter. Number of base condition cache misses.
*   `helios_cache_hit_ratio`: Gauge. (Hits / (Hits + Misses)).
    *   *Target*: > 90%.

=== 1.3. Evaluation Internals
*   `helios_predicates_evaluated_total`: Counter. Number of individual predicates evaluated.
*   `helios_vector_operations_total`: Counter. Number of vectorized (SIMD) evaluations.

== 2. Alerts

Recommended alert thresholds for production environments.

[cols="1,1,2"]
|===
| Alert Name | Threshold | Description

| High Latency
| P99 > 5ms for 1m
| Evaluation latency is degrading. Check CPU usage and GC logs.

| Low Cache Hit Rate
| < 80% for 5m
| Base condition cache is ineffective. Investigate traffic patterns or cache size.

| High Error Rate
| > 1% for 1m
| Rule evaluation is failing. Check logs for exceptions.

| Memory Growth
| > 80% Heap for 5m
| Potential memory leak or insufficient heap size.

| Expansion Explosion
| Factor > 10,000
| A rule is generating too many combinations. Check rule definitions.
|===

== 3. Tracing

Helios uses OpenTelemetry for distributed tracing.

=== 3.1. Spans
*   `rule_engine.evaluate`: The parent span for a single event evaluation.
*   `rule_engine.compile`: Span for the compilation process (during hot reload).

=== 3.2. Attributes
Spans are enriched with the following attributes:
*   `event.id`: The unique ID of the processed event.
*   `rules.matched.count`: The number of rules that matched.
*   `engine.version`: The version of the `EngineModel` used.

== 4. Dashboards

A standard Grafana dashboard should include:
1.  **Overview**: Request rate, P99 latency, Error rate.
2.  **Cache Performance**: Hit rate, Eviction rate.
3.  **Rule Performance**: Matches per second, Predicates per event.
4.  **JVM Health**: Heap usage, GC pause times, CPU usage.
