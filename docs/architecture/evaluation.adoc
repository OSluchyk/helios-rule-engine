= Evaluation Pipeline

The evaluation pipeline is the high-performance runtime core responsible for matching incoming events against the compiled `EngineModel`. It is designed for sub-millisecond latency, high throughput, and zero-allocation operation on the hot path.

== 1. Pipeline Overview

The runtime execution flow for a single event consists of six stages:

1.  **Normalization & Encoding**
2.  **Base Condition Evaluation (Cached)**
3.  **Predicate Evaluation**
4.  **Counter Update**
5.  **Match Detection**
6.  **Selection**

== 2. Stage Details

=== Stage 1: Normalization & Encoding
*   **Input**: Raw `Event` object (Map-based attributes).
*   **Process**:
    *   Converts string attribute names and values into integer IDs using the `Dictionary`.
    *   Flattens the event into a dense integer array for fast index-based access.
    *   Applies default values and validates required fields.
*   **Benefit**: Eliminates expensive String hashing and Map lookups during the core evaluation loop.

=== Stage 2: Base Condition Evaluation (Cached)
*   **Concept**: Many rules share identical static conditions (e.g., `country == "US"`). These are factored out into "Base Condition Sets".
*   **Process**:
    *   Evaluates these static conditions first.
    *   Checks the `BaseConditionCache` (In-Memory or Redis) for pre-computed results.
    *   If cached, retrieves the `RoaringBitmap` of matching rules immediately.
*   **Benefit**: Reduces the number of predicates to evaluate by 90%+.

=== Stage 3: Predicate Evaluation
*   **Process**:
    *   Iterates through the remaining unique predicates in the `EngineModel`.
    *   Skips predicates that are already known to be false (from Base Conditions).
    *   Evaluates predicates in order of weight (cheapest & most selective first).
    *   Uses **Vectorization** (SIMD) to evaluate groups of predicates on the same field in parallel.

=== Stage 4: Counter Update
*   **Mechanism**: "Counter-Based Matching" (Rete-like).
*   **Process**:
    *   Maintains a `short[]` counter array, one slot per rule.
    *   For each true predicate, retrieves the list of affected rules (Posting List) from the Inverted Index.
    *   Increments the counter for each affected rule.
    *   Tracks "touched" rules to reset counters efficiently (O(touched) instead of O(all_rules)).

=== Stage 5: Match Detection
*   **Process**:
    *   Iterates only through the "touched" rules.
    *   Compares the rule's counter value against its required "Needs" count (number of conditions).
    *   If `counter == needs`, the rule is a match.
    *   Checks for any "Expanded Combinations" (from DNF expansion) that also matched.

=== Stage 6: Selection
*   **Process**: Applies the configured `SelectionStrategy` to the set of matched rules.
    *   `ALL_MATCHES`: Returns everything.
    *   `PER_FAMILY_MAX_PRIORITY`: Returns the highest priority rule for each logical rule family.
    *   `TOP_K`: Returns the top K matches globally.

== 3. Key Runtime Components

*   **`RuleEvaluator`**: The orchestrator of the pipeline.
*   **`EventEncoder`**: Handles dictionary encoding and array flattening.
*   **`BaseConditionEvaluator`**: Manages the caching and evaluation of static rule subsets.
*   **`EvaluationContext`**: A thread-local (or `ScopedValue`) object that holds reusable buffers (counters, touched lists) to ensure **Zero Allocation** per request.
*   **`RoaringBitmap`**: Used for efficient set operations (intersection, union) on rule IDs.

== 4. Performance Characteristics

*   **Latency**: P99 < 0.8ms for 100k rules.
*   **Throughput**: 15-20M events/minute on standard hardware.
*   **Memory**: Zero-allocation on the hot path (using object pooling).
*   **Concurrency**: Lock-free design; safe for high-concurrency environments.
